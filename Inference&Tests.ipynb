{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f52d475d06e472bb575ef9129fb85b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locked and loaded!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoProcessor, AutoModelForPreTraining\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "#Set the batch-size\n",
    "batch_size = 8\n",
    "# We already divided the test-set into 4-parts. \n",
    "# !!! If you have a central name please update the path !!!\n",
    "# 1. Path to update\n",
    "data_dir = \"/teamspace/studios/this_studio/images/\" \n",
    "# 2. Path to update\n",
    "metadata_df = pd.read_csv(\"/teamspace/studios/this_studio/test.csv\")\n",
    "\n",
    "\n",
    "device = \"cuda\"\n",
    "model_id = \"google/paligemma-3b-ft-docvqa-448\"\n",
    "config = PeftConfig.from_pretrained(\"adithyabalagoni11/pali-gemma-ft-ml-challenge\")\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "base_model = AutoModelForPreTraining.from_pretrained(\"google/paligemma-3b-ft-docvqa-448\").to(device)\n",
    "peft_model = PeftModel.from_pretrained(base_model, \"adithyabalagoni11/pali-gemma-ft-ml-challenge\").to(device)\n",
    "base_model.eval()\n",
    "print(\"Locked and loaded!\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 623/623 [1:09:01<00:00,  6.65s/it]\n"
     ]
    }
   ],
   "source": [
    "pred_vals = {\"predictions\":[], \"img_name\": [],'labels':[]}\n",
    "# Prepare batch inference\n",
    "import random\n",
    "error_files = \"\"\n",
    "def extract_value(response):\n",
    "    try:\n",
    "        return response.split('\\n')[-1].strip()\n",
    "    except IndexError:\n",
    "        return response  \n",
    "#The for-loop was used for batch-inference as using test-loaders was giving errors\n",
    "batch_size=8\n",
    "for batch_start in tqdm(range(0, len(metadata_df), batch_size)):\n",
    "    batch_end = min(batch_start + batch_size, len(metadata_df))\n",
    "\n",
    "    #Updating the batch\n",
    "    batch_images = []\n",
    "    batch_prompts = []\n",
    "    for idx in range(batch_start, batch_end):\n",
    "        img_path =  data_dir +  metadata_df[\"image\"][idx]\n",
    "        pred_vals[\"img_name\"].append(metadata_df[\"image\"][idx])\n",
    "        name=metadata_df[\"entity_name\"][idx]\n",
    "        parsed=name.split(' ')[3].replace('?','')\n",
    "        forma=f\"\"\"\" the {name} is  \"\"\"\n",
    "        prompt =name +forma\n",
    "\n",
    "        # Using img_path to load the image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # (IMG,PROMPT) batch\n",
    "        batch_images.append(image)\n",
    "        batch_prompts.append(prompt)\n",
    "\n",
    "    #Pre-processing the batch\n",
    "    model_inputs = processor(text=batch_prompts, images=batch_images, return_tensors=\"pt\", padding=True).to(device)\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        generation = base_model.generate(**model_inputs, max_new_tokens=100, do_sample=False)\n",
    "        \n",
    "    decoded = processor.batch_decode(generation, skip_special_tokens=True)\n",
    "    # values=decoded\n",
    "    # print(values)\n",
    "    values = [extract_value(response) for response in decoded]\n",
    "    # print(values)\n",
    "    # print(random.sample(values,k=2))\n",
    "    pred_vals[\"predictions\"].extend(values)\n",
    "    # if batch_start % 200 == 0 and batch_start > 0:\n",
    "    #     pred_df = pd.DataFrame(pred_vals)\n",
    "    #     pred_df.to_csv(f\"test_set_{test_id}_pred_palli_final.csv\", index=False)\n",
    "pred_vals['labels']=metadata_df['entity_value'].tolist()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(pred_vals)\n",
    "entity_unit_map = {\n",
    "  \"width\": [\n",
    "    \"centimetre\",\n",
    "    \"foot\",\n",
    "    \"millimetre\",\n",
    "    \"metre\",\n",
    "    \"inch\",\n",
    "    \"yard\"\n",
    "  ],\n",
    "  \"depth\": [\"centimetre\",\n",
    "    \"foot\",\n",
    "    \"millimetre\",\n",
    "    \"metre\",\n",
    "    \"inch\",\n",
    "    \"yard\"\n",
    "  ],\n",
    "  \"height\": [\n",
    "    \"centimetre\",\n",
    "    \"foot\",\n",
    "    \"millimetre\",\n",
    "    \"metre\",\n",
    "    \"inch\",\n",
    "    \"yard\"\n",
    "  ],\n",
    "  \"item_weight\": [\n",
    "    \"milligram\",\n",
    "    \"kilogram\",\n",
    "    \"microgram\",\n",
    "    \"gram\",\n",
    "    \"ounce\",\n",
    "    \"ton\",\n",
    "    \"pound\"\n",
    "  ],\n",
    "  \"maximum_weight_recommendation\": [\n",
    "    \"milligram\",\n",
    "    \"kilogram\",\n",
    "    \"microgram\",\n",
    "    \"gram\",\n",
    "    \"ounce\",\n",
    "    \"ton\",\n",
    "    \"pound\"\n",
    "  ],\n",
    "  \"voltage\": [\n",
    "    \"millivolt\",\n",
    "    \"kilovolt\",\n",
    "    \"volt\"\n",
    "  ],\n",
    "  \"wattage\": [\n",
    "    \"kilowatt\",\n",
    "    \"watt\"\n",
    "  ],\n",
    "  \"item_volume\": [\n",
    "    \"cubic foot\",\n",
    "    \"microlitre\",\n",
    "    \"cup\",\n",
    "    \"fluid ounce\",\n",
    "    \"centilitre\",\n",
    "    \"imperial gallon\",\n",
    "    \"pint\",\n",
    "    \"decilitre\",\n",
    "    \"litre\",\n",
    "    \"millilitre\",\n",
    "    \"quart\",\n",
    "    \"cubic inch\",\n",
    "    \"gallon\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "def parse_measurement(text, entity_unit_map):\n",
    "    \"\"\"\n",
    "    Parse measurement text to standardized 'value unit' format using only allowed units\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "        \n",
    "    text = str(text).lower().strip()\n",
    "    \n",
    "    # Unit mapping dictionary\n",
    "    unit_mapping = {\n",
    "        # Length\n",
    "        'cm': 'centimetre',\n",
    "        'mm': 'millimetre',\n",
    "        'm': 'metre',\n",
    "        'in': 'inch',\n",
    "        'inch': 'inch',\n",
    "        '\"': ' ',\n",
    "        'inches': 'inch',\n",
    "        'ft': 'foot',\n",
    "        'feet': 'foot',\n",
    "        'yd': 'yard',\n",
    "        \n",
    "        # Weight\n",
    "        'g': 'gram',\n",
    "        'grams': 'gram',\n",
    "        'kg': 'kilogram',\n",
    "        'mg': 'milligram',\n",
    "        'µg': 'microgram',\n",
    "        'oz': 'ounce',\n",
    "        'lbs': 'pound',\n",
    "        'lb': 'pound',\n",
    "        \n",
    "        # Volume\n",
    "        'ml': 'millilitre',\n",
    "        'l': 'litre',\n",
    "        'cl': 'centilitre',\n",
    "        'dl': 'decilitre',\n",
    "        'fl oz': 'fluid ounce',\n",
    "        'gal': 'gallon',\n",
    "        'pt': 'pint',\n",
    "        'qt': 'quart',\n",
    "        'cu in': 'cubic inch',\n",
    "        'cu ft': 'cubic foot',\n",
    "        \n",
    "        # Electrical\n",
    "        'v': 'volt',\n",
    "        'mv': 'millivolt',\n",
    "        'kv': 'kilovolt',\n",
    "        'w': 'watt',\n",
    "        'kw': 'kilowatt'\n",
    "    }\n",
    "    \n",
    "    # Clean text\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)  # Remove parentheses content\n",
    "    \n",
    "    # Modified pattern to capture number followed by unit\n",
    "    pattern = r'(\\d*\\.?\\d+)\\s*([a-zA-Z\"\\']+|(?:fl oz)|(?:cu ft)|(?:cu in))'\n",
    "    matches = re.finditer(pattern, text)\n",
    "    \n",
    "    try:\n",
    "        # Get first match\n",
    "        match = next(matches)\n",
    "        value = float(match.group(1))\n",
    "        unit_text = match.group(2).strip().lower()\n",
    "        \n",
    "        # Get all valid units from entity_unit_map\n",
    "        valid_units = set()\n",
    "        for units in entity_unit_map.values():\n",
    "            valid_units.update(units)\n",
    "            \n",
    "        # Try to find matching unit\n",
    "        found_unit = None\n",
    "        \n",
    "        # First check unit_mapping\n",
    "        if unit_text in unit_mapping and unit_mapping[unit_text] in valid_units:\n",
    "            found_unit = unit_mapping[unit_text]\n",
    "            \n",
    "        # Then check valid_units directly\n",
    "        if not found_unit:\n",
    "            for valid_unit in valid_units:\n",
    "                if valid_unit.lower().startswith(unit_text):\n",
    "                    found_unit = valid_unit\n",
    "                    break\n",
    "        if value.is_integer():\n",
    "            value=int(value)\n",
    "        if found_unit:\n",
    "            return f\"{value} {found_unit}\"\n",
    "            \n",
    "    except (StopIteration, ValueError):\n",
    "        pass\n",
    "        \n",
    "    return \"\"\n",
    "\n",
    "def process_predictions(df, prediction_col, entity_unit_map=entity_unit_map):\n",
    "    \"\"\"\n",
    "    Process predictions column and create new standardized column\n",
    "    \"\"\"\n",
    "    df['parsed_predictions'] = df[prediction_col].apply(\n",
    "        lambda x: parse_measurement(x, entity_unit_map)\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "pred_df=process_predictions(pred_df,'predictions')\n",
    "pred_df.to_csv('test_pali-gemma-base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vals = {\"predictions\":[], \"img_name\": [],'labels':[]}\n",
    "# Prepare batch inference\n",
    "import random\n",
    "def extract_value(response):\n",
    "    try:\n",
    "        return response.split('\\n')[-1].strip()\n",
    "    except IndexError:\n",
    "        return response  \n",
    "#The for-loop was used for batch-inference as using test-loaders was giving errors\n",
    "batch_size=8\n",
    "for batch_start in tqdm(range(0, len(metadata_df), batch_size)):\n",
    "    batch_end = min(batch_start + batch_size, len(metadata_df))\n",
    "\n",
    "    #Updating the batch\n",
    "    batch_images = []\n",
    "    batch_prompts = []\n",
    "    for idx in range(batch_start, batch_end):\n",
    "        img_path =  data_dir +  metadata_df[\"image\"][idx]\n",
    "        pred_vals[\"img_name\"].append(metadata_df[\"image\"][idx])\n",
    "        name=metadata_df[\"entity_name\"][idx]\n",
    "        parsed=name.split(' ')[3].replace('?','')\n",
    "        forma=f\"\"\"\" the {name} is  \"\"\"\n",
    "        prompt =name +forma\n",
    "\n",
    "        # Using img_path to load the image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # (IMG,PROMPT) batch\n",
    "        batch_images.append(image)\n",
    "        batch_prompts.append(prompt)\n",
    "\n",
    "    #Pre-processing the batch\n",
    "    model_inputs = processor(text=batch_prompts, images=batch_images, return_tensors=\"pt\", padding=True).to(device)\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        generation = peft_model.generate(**model_inputs, max_new_tokens=100, do_sample=False)\n",
    "        \n",
    "    decoded = processor.batch_decode(generation, skip_special_tokens=True)\n",
    "    # values=decoded\n",
    "    # print(values)\n",
    "    values = [extract_value(response) for response in decoded]\n",
    "    # print(values)\n",
    "    # print(random.sample(values,k=2))\n",
    "    pred_vals[\"predictions\"].extend(values)\n",
    "    # if batch_start % 200 == 0 and batch_start > 0:\n",
    "    #     pred_df = pd.DataFrame(pred_vals)\n",
    "    #     pred_df.to_csv(f\"test_set_{test_id}_pred_palli_final.csv\", index=False)\n",
    "pred_vals['labels']=metadata_df['entity_value'].tolist()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(pred_vals)\n",
    "pred_df.to_csv(\"test_pali-gemma-ft-ml-challenge.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(csv,pred_column):\n",
    "    df=pd.read_csv(csv)\n",
    "    predictions,labels=df[pred_column].tolist(),df['labels'].tolist()\n",
    "\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    true_negatives = 0\n",
    "    \n",
    "    # Calculate metrics based on the problem's criteria\n",
    "    for pred, gt in zip(predictions, labels):\n",
    "        if pred != \"\" and gt != \"\":\n",
    "            if pred == gt:\n",
    "                true_positives += 1\n",
    "            else:\n",
    "                false_positives += 1\n",
    "        elif pred != \"\" and gt == \"\":\n",
    "            false_positives += 1\n",
    "        elif pred == \"\" and gt != \"\":\n",
    "            false_negatives += 1\n",
    "        else:  # pred == \"\" and gt == \"\"\n",
    "            true_negatives += 1\n",
    "    \n",
    "    # Calculate precision and recall\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    accuracy=(true_positives+true_negatives)/(true_positives+true_negatives+false_positives+false_negatives)\n",
    "    # Compile metrics\n",
    "    metrics = {\n",
    "        \"f1_score\": f1_score,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"exact_match ( out of 5000 examples )\": true_positives,\n",
    "        'accuracy':accuracy \n",
    "    }\n",
    "    for key in metrics:\n",
    "        print(f\"{key} : {metrics[key]} \")\n",
    "    \n",
    "    return metrics    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score : 0.5969854909142133 \n",
      "precision : 0.4255020080321285 \n",
      "recall : 1.0 \n",
      "exact_match ( out of 5000 examples ) : 2119 \n",
      "accuracy : 0.4255020080321285 \n"
     ]
    }
   ],
   "source": [
    "result=compute_metrics(\"test_pali-gemma-base.csv\",'parsed_predictions')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score : 0.7080036321183033 \n",
      "precision : 0.547991967871486 \n",
      "recall : 1.0 \n",
      "exact_match ( out of 5000 examples ) : 2729 \n",
      "accuracy : 0.547991967871486 \n"
     ]
    }
   ],
   "source": [
    "result=compute_metrics(\"test_pali-gemma-ft-ml-challenge.csv\",'predictions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
